#!/usr/bin/env python
# Usage: examples/logistic_regression examples.db:track_hello
from sys import argv
from itertools import groupby, islice
from operator import itemgetter
from random import Random

import matplotlib
matplotlib.use("pdf")
import matplotlib.pyplot as plt

import twitterology as tw
import twitterology.features as tf


import numpy as np
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import roc_curve, auc

from tqdm import tqdm


def take_samples(
        timelines, similar_pairs, distinct_pairs,
        extract_features,
        description
):
    random = Random(42)
    timelines = islice(timelines, similar_pairs)

    timeline_samples = []
    for _, timeline in tqdm(timelines, total=similar_pairs, desc=description + " (step 1)"):
        timeline = list(timeline)
        half_length = len(timeline) / 2

        earlier = extract_features.features(timeline[:half_length])
        later = extract_features.features(timeline[half_length:])

        timeline_samples.append((earlier, later))

    samples = []
    targets = []

    for (earlier, later) in tqdm(timeline_samples, desc=description + " (step 2)"):
        samples.append(extract_features(earlier, later))
        targets.append(1)

    for _ in tqdm(range(distinct_pairs), desc=description + " (step 3)"):
        (earlier, _), (_, later) = random.sample(timeline_samples, 2)
        samples.append(extract_features(earlier, later))
        targets.append(0)

    samples = np.array(samples)
    targets = np.array(targets)

    return samples, targets


def plot_features(samples, targets, extract_features):
    plt.figure(figsize=(6, 15))
    plt.subplots_adjust(hspace=0.5)

    for index, (distribution, label) in enumerate(zip(samples.T, extract_features.features.labels), start=1):
        plt.subplot(len(extract_features.features.labels), 1, index)
        for target in [0, 1]:
            mask = (targets == target).astype(int)
            density, edges = np.histogram(distribution, weights=mask, bins=23, density=True)

            plt.plot(edges[1:], density, label=str(target))
            plt.title(label.decode("utf-8"))
    plt.savefig("features")


def main():
    database, table = argv[1].split(":")
    storage = tw.sources.sqlite(database, table)

    tweets = storage.find(order_by="user__id_str")
    timelines = groupby(tweets, itemgetter("user__id_str"))

    extract_features = tf.ProductDifference(
        tf.AbsoluteDifference(
            tf.Product(
                tf.Median(tf.Length()),
                tf.Average(tf.IsRetweet()),
                tf.Average(tf.Count(tf.Hashtags())),
                tf.Average(tf.Count(tf.Mentions())),
                tf.Average(tf.IncludesLink()),

                tf.AverageInterval(),
                tf.Diversity()
            )
        ),
        tf.JaccardDifference(
            tf.Counts(tf.Hashtags(), top=4)
        )
    )

    train_samples, train_targets = take_samples(
        timelines, 2000, 64000, extract_features, "Training"
    )
    clf = LogisticRegression()
    clf.fit(train_samples, train_targets)

    test_samples, test_targets = take_samples(
        timelines, 10000, 320000, extract_features, "Testing"
    )
    print "Score:", clf.score(test_samples, test_targets)

    decision = clf.decision_function(test_samples)
    fprs, tprs, _ = roc_curve(test_targets, decision)

    roc_auc = auc(fprs, tprs)
    print "Auc:", roc_auc

    plt.figure(figsize=(6, 4))
    plt.plot(fprs, tprs, label="AUC: {}".format(roc_auc))
    plt.legend(loc="lower right")

    plt.savefig("roc")

    plot_features(test_samples, test_targets, extract_features)


if __name__ == "__main__":
    main()

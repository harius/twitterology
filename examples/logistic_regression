#!/usr/bin/env python
# Usage: examples/logistic_regression examples.db:track_hello
from sys import argv
from itertools import groupby, islice
from operator import itemgetter

import matplotlib
matplotlib.use("Agg")
import matplotlib.pyplot as plt

import twitterology as tw
import twitterology.features as tf


import numpy as np
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import roc_curve, auc

from tqdm import tqdm


def iter_samples(extract_features, timelines):
    previous_samples = []
    for _, timeline in timelines:
        timeline = list(timeline)
        half_length = len(timeline) / 2

        earlier = extract_features.features(timeline[:half_length])
        later = extract_features.features(timeline[half_length:])

        for previous in previous_samples:
            yield extract_features(previous, later), 0
        previous_samples.append(earlier)

        yield extract_features(earlier, later), 1


def obtain_samples(extract_features, timelines, length, desc):
    samples = []
    targets = []

    for sample, target in iter_samples(
            extract_features,
            tqdm(islice(timelines, length), total=length, desc=desc)
    ):
        samples.append(sample)
        targets.append(target)

    samples = np.array(samples)
    targets = np.array(targets)

    return samples, targets


def main():
    database, table = argv[1].split(":")
    storage = tw.sources.sqlite(database, table)

    tweets = storage.find(order_by="user__id_str")
    timelines = groupby(tweets, itemgetter("user__id_str"))

    extract_features = tf.ProductDifference(
        tf.AbsoluteDifference(
            tf.Product(
                tf.Median(tf.Length()),
                tf.Average(tf.Retweet()),
                tf.Average(tf.Count(tf.Hashtags())),
                tf.Average(tf.Count(tf.Mentions())),
                # t.co links?
                # Ordinary links?

                tf.AverageInterval(),
                tf.Diversity()
            )
        ),
        tf.JaccardDifference(
            tf.Counts(tf.Hashtags(), top=3)
        )
    )

    train_samples, train_targets = obtain_samples(
        extract_features, timelines, 1000, "Training"
    )
    clf = LogisticRegression()
    clf.fit(train_samples, train_targets)

    test_samples, test_targets = obtain_samples(
        extract_features, timelines, 1000, "Testing"
    )
    print "Score:", clf.score(test_samples, test_targets)

    decision = clf.decision_function(test_samples)
    fprs, tprs, _ = roc_curve(test_targets, decision)

    roc_auc = auc(fprs, tprs)
    print "Auc:", roc_auc
    plt.plot(fprs, tprs, label="AUC: {}".format(roc_auc))
    plt.legend(loc="lower right")

    plt.savefig("roc.png")


if __name__ == "__main__":
    main()
